{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'py (Python 3.10.9)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# parameters\n",
    "model_name = \"pierreguillou/ner-bert-large-cased-pt-lenerbr\"\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "input_text = \"Acrescento que não há de se falar em violação do artigo 114, § 3º, da Constituição Federal, posto que referido dispositivo revela-se impertinente, tratando da possibilidade de ajuizamento de dissídio coletivo pelo Ministério Público do Trabalho nos casos de greve em atividade essencial.\"\n",
    "\n",
    "# tokenization\n",
    "inputs = tokenizer(input_text, max_length=512, truncation=True, return_tensors=\"pt\")\n",
    "tokens = inputs.tokens()\n",
    "\n",
    "# get predictions\n",
    "outputs = model(**inputs).logits\n",
    "predictions = torch.argmax(outputs, dim=2)\n",
    "\n",
    "# print predictions\n",
    "for token, prediction in zip(tokens, predictions[0].numpy()):\n",
    "    print((token, model.config.id2label[prediction]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (AutoModelForTokenClassification, \n",
    "                          AutoTokenizer, \n",
    "                          convert_pytorch_checkpoint_to_tf2)\n",
    "\n",
    "# Carregue o modelo e o tokenizador\n",
    "model_name = \"pierreguillou/ner-bert-large-cased-pt-lenerbr\"\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Defina os nomes para os arquivos de modelo TensorFlow\n",
    "tf_model_path = \"tf_ner_bert_large_cased_pt_lenerbr\"\n",
    "\n",
    "# Converta o modelo\n",
    "convert_pytorch_checkpoint_to_tf2.convert_pt_checkpoint_to_tf(\n",
    "    model=model,\n",
    "    ckpt_dir=tf_model_path,\n",
    "    model_name=\"tf_ner_bert_large_cased_pt_lenerbr\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForTokenClassification\n",
    "\n",
    "# Carregue o modelo TensorFlow\n",
    "tf_model = TFAutoModelForTokenClassification.from_pretrained(tf_model_path, from_pt=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
